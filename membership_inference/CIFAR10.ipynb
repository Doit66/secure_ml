{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "handled-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "from membership_inference import DataSet, ShadowModel, AttackerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "composite-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-reform",
   "metadata": {},
   "source": [
    "# Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "twelve-testimony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf12490cddd4653bdba8bbb846c9d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# トレーニングデータをダウンロード\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "# テストデータをダウンロード\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "affected-jacob",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000,)\n",
      "(10000, 32, 32, 3) (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = trainset.data\n",
    "y_train = np.array(trainset.targets)\n",
    "\n",
    "X_test = testset.data\n",
    "y_test = np.array(testset.targets)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "strange-essence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 32, 32, 3) (1000,)\n",
      "(1000, 32, 32, 3) (1000,)\n",
      "(1000, 32, 32, 3) (1000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "victim_idx = random.sample(range(X_train.shape[0]), k=1000)\n",
    "attack_idx = random.sample(range(X_test.shape[0]), k=2000)\n",
    "shadow_idx = attack_idx[:1000]\n",
    "eval_idx = attack_idx[1000:]\n",
    "\n",
    "X_victim = X_train[victim_idx]\n",
    "y_victim = y_train[victim_idx]\n",
    "\n",
    "X_shadow = X_test[shadow_idx]\n",
    "y_shadow = y_test[shadow_idx]\n",
    "\n",
    "X_eval = X_test[eval_idx]\n",
    "y_eval = y_test[eval_idx]\n",
    "\n",
    "print(X_victim.shape, y_victim.shape)\n",
    "print(X_shadow.shape, y_shadow.shape)\n",
    "print(X_eval.shape, y_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rapid-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToTensor：画像のグレースケール化（RGBの0~255を0~1の範囲に正規化）、Normalize：Z値化（RGBの平均と標準偏差を0.5で決め打ちして正規化）\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "victimset = DataSet(X_victim, y_victim, transform=transform)\n",
    "victimloader = torch.utils.data.DataLoader(victimset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "valset = DataSet(X_eval, y_eval, transform=transform)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-modification",
   "metadata": {},
   "source": [
    "# Define and Train a victim Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adequate-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNを実装する\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        #x = F.softmax(x, dim=0)\n",
    "        return x\n",
    "\n",
    "victim_net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "proprietary-notebook",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.142\n",
      "0.193\n",
      "0.255\n",
      "0.252\n",
      "0.296\n",
      "0.34\n",
      "0.35\n",
      "0.309\n",
      "0.348\n",
      "0.348\n",
      "Finished Training\n",
      "0.539\n",
      "0.348\n"
     ]
    }
   ],
   "source": [
    "# 交差エントロピー\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 確率的勾配降下法\n",
    "optimizer = optim.SGD(victim_net.parameters(), lr=0.005, momentum=0.9)\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(victimloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = victim_net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    test_preds = []\n",
    "    test_label = []\n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            inputs, labels = data\n",
    "            outputs = victim_net(inputs)\n",
    "            test_preds.append(outputs)\n",
    "            test_label.append(labels)  \n",
    "        test_preds = torch.cat(test_preds)\n",
    "        test_label = torch.cat(test_label)  \n",
    "\n",
    "    print(accuracy_score(np.array(torch.argmax(test_preds, axis=1)), np.array(test_label)))\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "in_preds = []\n",
    "in_label = []\n",
    "with torch.no_grad():\n",
    "        for data in victimloader:\n",
    "            inputs, labels = data\n",
    "            outputs = victim_net(inputs)\n",
    "            in_preds.append(outputs)\n",
    "            in_label.append(labels)  \n",
    "        in_preds = torch.cat(in_preds)\n",
    "        in_label = torch.cat(in_label)  \n",
    "print(accuracy_score(np.array(torch.argmax(in_preds, axis=1)),\n",
    "                     np.array(in_label)))\n",
    "\n",
    "out_preds = []\n",
    "out_label = []\n",
    "with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            inputs, labels = data\n",
    "            outputs = victim_net(inputs)\n",
    "            out_preds.append(outputs)\n",
    "            out_label.append(labels)  \n",
    "        out_preds = torch.cat(out_preds)\n",
    "        out_label = torch.cat(out_label)  \n",
    "print(accuracy_score(np.array(torch.argmax(out_preds, axis=1)),\n",
    "                     np.array(out_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-doubt",
   "metadata": {},
   "source": [
    "# Define and Train ShadowModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "conditional-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNを実装する\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "perceived-opportunity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "sm = ShadowModel([Net(), Net(),Net(), Net(), Net()], 400, shadow_transform=transform)\n",
    "y_test = np.array(y_test)\n",
    "result = sm.fit_transform(X_test, y_test, num_itr=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-graphics",
   "metadata": {},
   "source": [
    "# Attacker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "floral-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "models = [SVC() for i in range(len(result.keys()))]\n",
    "am = AttackerModel(models)\n",
    "am.fit(result)\n",
    "\n",
    "attack_pred_in = am.predict(in_preds, in_label)\n",
    "attack_pred_out = am.predict(out_preds, out_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
